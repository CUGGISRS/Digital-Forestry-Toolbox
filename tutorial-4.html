<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="UTF-8">
        <title>DFT - Tutorial 4</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="shortcut icon" type="image/png" href="img/favicon_dft.png"/>
        <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
        <link rel='stylesheet' type='text/css' href='https://fonts.googleapis.com/css?family=Open+Sans:400,700'>
        <link rel='stylesheet' type='text/css' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css' >
        <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
        <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
        <link rel="stylesheet" type="text/css" href="lib/ol-v5.3.0/ol.css" media="screen">
        <link rel="stylesheet" type="text/css" href="lib/ol-layerswitcher/ol-layerswitcher.css">

        <!--     <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.1/css/all.css" integrity="sha384-gfdkjb5BdAXd+lj+gudLWI+BXq4IuLW5IT+brZEZsLFm++aCMlF1V92rMkPaX4PP" crossorigin="anonymous">
-->
        <script src="lib/ol-v5.3.0/ol.js"></script>
        <script src="lib/proj4js-2.5.0/proj4.js"></script>
        <script src="lib/ol-layerswitcher/ol-layerswitcher.js"></script>
        <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>

        <style>
            .map:-moz-full-screen {
                height: 100%;
            }
            .map:-webkit-full-screen {
                height: 100%;
            }
            .map:-ms-fullscreen {
                height: 100%;
            }
            .map:fullscreen {
                height: 100%;
            }
            /* position the rotate control lower than usual */
            .ol-rotate {
                top: 3em;
            }
            
            .ol-custom{
              position: relative;
              z-index: 1000;
            }
            
            #map2 {
             position: relative;
            }
            
            .slidecontainer {
              position: absolute;
              margin: auto;
              left:0;
              right:0;
              width: 300px;
              max-width: 40%;
              height: 30px;
              top: 2.5rem;
              z-index: 99; 
            }
                       
            .slider {
              -webkit-appearance: none;
              width:100%;
              height: 20px;
              border-radius: 5px;   
              background: rgba(255,255,255,0.9); /*#d3d3d3;*/
              outline: none;
              opacity: 0.7;
              -webkit-transition: .2s;
              transition: opacity .2s;
            }
            .slider::-webkit-slider-thumb {
              -webkit-appearance: none;
              appearance: none;
              top: 10rem;
              width: 30px;
              height: 30px;
              border-radius: 50%; 
              background: rgba(0,0,0,0.95); /* rgb(91, 117, 109);*/
              cursor: pointer;
            }
            .slider::-moz-range-thumb {
              top: 10rem;    
              width: 30px;
              height: 30px;
              border-radius: 50%;
              background: rgba(0,0,0,0.9); /* rgb(91, 117, 109);*/
              cursor: pointer;
            }
            
        </style>

    </head>

    <body>

        <section class="page-header tutorial">
            <h1 class="project-name">Digital-Forestry-Toolbox</h1>
            <br>
            <a href="index.html" class="btn"><i class="fa fa-home" aria-hidden="true"></i> Back to homepage</a>
        </section>

        <section class="main-content">

            <h1>Deciduous/evergreen foliage classification</h1>

            <p style="text-align: center"><i class="fa fa-info-circle fa-2x" aria-hidden="true"></i></p>
            <p style="text-align: center"><b>Published</b>: April 29, 2019 / <b>Last updated</b>: April 29, 2019</p>
            <p style="text-align: center"><b>Tested on Matlab r2018b, GNU Octave 5.1.0</b></p>

            <h2>
                <a id="introduction" class="anchor" href="introduction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Introduction</b>
            </h2>

            <p>This tutorial presents a simple approach to differentiate deciduous and evergreen foliage using the corrected return intensity of Airborne Laser Scanning (ALS) data. Foliage persistance maps can for example be useful to improve stem diameter prediction (by applying deciduous/evergreen specific allometric models) and for wildlife habitat modelling. This distinction is <b>not to be confused with the distinction of broadleaf and coniferous</b>, as some coniferous trees, such as larches, will shed their needles in automn while some broadleaf trees, such as hollies, will keep their leaves in winter.</p> 
            <p>Dense foliage and large branches have a higher probability of completely intercepting the laser beam and generating single high intensity returns (see figures 1 and 2). Moreover, most LiDAR systems employ near infrared light which is strongly reflected by live foliage. Thus, ALS data acquired during leaf-off conditions can be readily used to differentiate deciduous and evergreen foliage. It has also been repeatedly demonstrated that the return intensity and ranking distributions of laser scans are important features to differentiate tree species (e. g. <a href="#references">Liang et al., 2007; Ørka et al. 2009; Shi et al., 2018</a>).</p>  
            
            <br>
            <figure>
                <img src="img/dft_tutorial_4_ima_1a.png" alt="" style="width:80%;">
                <figcaption><b>Figure 1</b> - Conceptual example of the opacity difference under leaf-off conditions between birch (left) and spruce (right) trees. Low structural opacity will typically result in multiple low intensity returns. On the contrary, high structural opacity will tend to result in fewer high intensity returns.</figcaption>
            </figure>
            
            <figure>
                <img src="img/dft_tutorial_4_ima_2.png" alt="" style="width:80%;">
                <figcaption><b>Figure 2</b> - Example of difference in return intensity between a birch (left) and a spruce (right) tree in leaf-off conditions. Data courtesty of Geneva state (2017).</figcaption>
            </figure>
            <br>
            

             <p>However, due to various instrumental and environmental effects, the raw intensity is generally inconsistent accross the surveyed area and cannot be directly used as a discriminative feature; it should first be corrected (<a href="#references">Höfle and Pfeifer, 2007; Vain and Kaasalainen, 2011; Kashani et al., 2015</a>). This can be a complex task, as the return intensity (a proxy of the power reflected by the target surface and received by the sensor) depends on parameters which can be difficult to estimate, as shown in the RaDAR/LiDAR range equation below:</p>
            
            <br>
            
            $$P_r = \frac{D_{r}^2 \eta_{atm} \eta_{sys} \sigma P_t}{4 \pi R^4 \beta_{t}^2 }$$

            $$\sigma = \frac{4 \pi}{\Omega} \rho A_t$$
        
        
            <p>where:</p>

            <ul style="list-style-type:none">
                <li> \(P_r\) is the received power [W];</li>
                <li> \(P_t\) is the transmitted power [W];</li>
                <li> \(D_r\) is the aperture diameter [m];</li>
                <li> \(\eta_{atm}\) is the atmospheric transmittance;</li>
                <li> \(\eta_{sys}\) is the system transmittance;</li>
                <li> \(\sigma\) is the effective target cross-section [m<sup>2</sup>];</li>
                <li> \(R\) is the range from sensor to target [m];</li>
                <li> \(\beta_{t}\) is the width of the laser beam [m];</li>
                <li> \(\Omega\) is the scattering <a href="https://en.wikipedia.org/wiki/Solid_angle">solid angle</a> [sr];</li>
                <li> \(\rho\) is the reflectance of the target;</li>
                <li> \(A_t\) is the area of the target, i.e. area illuminated by the laser [m<sup>2</sup>].</li>
            </ul>
            
            <p>The RaDAR/LiDAR range equation can be simplified, if we assume that the target is a <a href="https://en.wikipedia.org/wiki/Lambertian_reflectance">Lambertian surface</a>, that it has a scattering solid angle \(\Omega = \pi\) [sr] and that the entire laser beam is intercepted (<a href="#references">Höfle and Pfeifer, 2007</a>). Under these assumptions, the area of the target \(A_t\) and its effective cross section \(\sigma\) respectively become:</p>
                
             $$A_t = \frac{\pi R^2 \beta_{t}^2}{4}$$
            
             $$\sigma = \pi \rho R^2 \beta_{t}^2 cos(\alpha)$$   
            
            <p>where:</p>

            <ul style="list-style-type:none">
                <li> \(\alpha\) is the angle between the surface normal and the laser beam.</li>
            </ul>
            
            <p>The received power \(P_r\) is then:</p>
            
             $$P_r = \frac{P_t D_{r}^2 \rho}{4 R^2} \eta_{atm} \eta_{sys} cos(\alpha)$$
                

            <p>This shows that the range between the sensor and the target surface has a large influence (quadratic in this case) on the received power (received intensity). To compensate the decay of intensity with range, a correction can be applied, if the aircraft trajectory and return times are known, following for example the guidelines provided in <a href="#references">Luzum et al. (2004)</a>:</p>
            
        
            $$I_{n} = I \cdot \left(\frac{R}{R_{ref}}\right)^2$$


            <p>where:</p>
        
            <ul style="list-style-type:none">
                <li> \(I_n\) is the range normalized intensity;</li>
                <li> \(I\) is the raw intensity;</li>
                <li> \(R\) is the range from sensor to target [m];</li>
                <li> \(R_{ref}\) is an arbitrary constant reference range (e. g. 1000 m).</li>
            </ul>
        
            
            <p>Altough none of the modelling assumptions used above are realistic when dealing with complex objects such as trees, this simple range correction may help homogenise intensity values accross the dataset. ALS post-processing software generally offer the possibility to apply some form of intensity correction. Riegl's RiProcess software, for example, lets you export either the amplitude (range dependent value) or a range independant value which they call reflectance to the "intensity" field in LAS files (<a href="#references">Riegl Laser Measurement Systems, 2017</a>). In this tutorial, we will use data acquired over the state of Geneva (Switzerland) in February 2017 (leaf-off conditions) with the <a href="http://www.riegl.com/nc/products/airborne-scanning/">Riegl LMS-Q1560</a> sensor. The data is openly available from <a href="https://ge.ch/sitg/donnees">Geneva's Official Geodata Portal</a>. <b>The intensity stored in the LAS file is the reflectance (i.e. range independent value) scaled to a 16 bit range (0-65535), so no further range correction is required</b>. If you would like to apply the approach illustrated in this tutorial to other ALS datasets, you should first inquire if and how the intensity has been processed.</p>
            
            <p>A small forest located about 10 km to the North of Geneva city (see map below) will serve as our study case. Within this area, the main tree species are pedunculate oak (<i>Quercus robur</i>) and Scots pine (<i>Pinus sylvestris</i>).</p>

            <div id="map1">

                <iframe src='https://map.geo.admin.ch/embed.html?topic=ech&lang=en&bgLayer=ch.swisstopo.swissimage&layers=ch.swisstopo.zeitreihen,ch.bfs.gebaeude_wohnungs_register,ch.bav.haltestellen-oev,ch.swisstopo.swisstlm3d-wanderwege&layers_visibility=false,false,false,false&layers_timestamp=18641231,,,&E=2499604.02&N=1127554.43&zoom=8' width='100%' height='450' frameborder='0'></iframe>

            </div>
    

            <h2>
                <a id="setup" class="anchor" href="setup" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Setup</b>
            </h2>

            <ol>
                <li>Download and uncompress the Digital Forestry Toolbox (DFT) <a href="https://github.com/mparkan/Digital-Forestry-Toolbox/zipball/master">Zip</a> or <a href="https://github.com/mparkan/Digital-Forestry-Toolbox/tarball/master">Tar</a> archive</li>
                <li>Download the <a href="https://zenodo.org/record/1998192/files/ge_2017_a.laz?download=1">ge_2017_a.laz</a> file from the DFT Zenodo repository and uncompress it with <a href="http://www.laszip.org/">LASzip</a></li>
                <li>Start Matlab/Octave</li>
                <li>Delete any previous versions of the toolbox</li>
                <li>Add the DFT folders to the Matlab/Octave search path using <code>addpath(genpath('path to DFT main folder'))</code></li>
                <li>Open <code>dft_tutorial_4.m</code> (located in the tutorials folder)</li>
            </ol>

            <h2>
                <a id="step-1" class="anchor" href="step-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 1</b> - Reading the LAS file
            </h2>

            <p>We start by reading the LAS file using <code>LASread()</code>:</p>

            <pre><code>pc = LASread('ge_2017_a.las');

xyz = [pc.record.x, pc.record.y, pc.record.z];
intensity = double(pc.record.intensity);</code></pre>

            <p>Note that you may have to adjust the file path in the code above, depending on where you are storing the LAS file. Also note that the point classification uses the following scheme:</p>

            <table>
                <thead>
                    <tr>
                        <th>Class</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>0</td>
                        <td>Created, never lassified</td>
                    </tr>
                    <tr>
                        <td>1</td>
                        <td>Unclassified</td>
                    </tr>
                    <tr>
                        <td>2</td>
                        <td>Terrain</td>
                    </tr>
                    <tr>
                        <td>3</td>
                        <td>Low vegetation (&lt; 50 cm)</td>
                    </tr>
                    <tr>
                        <td>5</td>
                        <td>High vegetation (&ge; 50 cm)</td>
                    </tr>
                    <tr>
                        <td>6</td>
                        <td>Buildings</td>
                    </tr>
                    <tr>
                        <td>7</td>
                        <td>Outliers and incorrect measurements (Low noise)</td>
                    </tr>
                    <tr>
                        <td>9</td>
                        <td>Water</td>
                    </tr>

                    <tr>
                        <td>13</td>
                        <td>Bridges</td>
                    </tr>
                    <tr>
                        <td>15</td>
                        <td>Terrain (additional points)</td>
                    </tr>
                    <tr>
                        <td>16</td>
                        <td>Outliers and incorrect measurements (High noise)</td>
                    </tr>
                    <tr>
                        <td>19</td>
                        <td>Points measured outside of the area of interest (unclassified)</td>
                    </tr>
                </tbody>
            </table>


            <h2>
                <a id="step-2" class="anchor" href="step-2" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 2</b> - Compute raster elevation models
            </h2>

            <p>In this step, we compute 1x1 m raster elevation models, using the <code>elevationModels()</code> function:</p>
            
        <pre><code>cellSize = 1;
[models, refmat] = elevationModels([pc.record.x, pc.record.y, pc.record.z], ...
    pc.record.classification, ...
    'classTerrain', [2, 9, 16], ...
    'classSurface', [3, 4, 5], ...
    'cellSize', cellSize, ...
    'closing', 3, ...
    'smoothingFilter', [], ...
    'outputModels', {'terrain', 'surface', 'height'}, ...
    'fig', true, ...
    'verbose', true);

% convert map coordinates to image coordinates
[nrows, ncols] = size(models.terrain.values);
P = [pc.record.x - refmat(3,1), pc.record.y - refmat(3,2)] / refmat(1:2,:);
row = round(P(:,1));
col = round(P(:,2));
ind = sub2ind([nrows, ncols], row, col);</code></pre>

            
             <h2>
                <a id="step-3" class="anchor" href="step-3" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 3</b> - Filter the canopy points 
            </h2>
            
            
            <p>We now create a filter which selects only high vegetation points located in the top highest 1 m section of the canopy:</p>

            <pre><code>idxl_veg = ismember(pc.record.classification, [4,5]);

z_margin = 1;
idxl_canopy = pc.record.z >= (models.surface.values(ind) - z_margin);
idxl_filter = idxl_veg & idxl_canopy;</code></pre>


            <h2>
                <a id="step-4" class="anchor" href="step-4" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 4</b> - Compute an intensity map
            </h2>

            <p>We create the intensity map by averaging the intensity of the canopy points located in each of the raster cells:</p>
        
            <pre><code>I = accumarray([row(idxl_filter), col(idxl_filter)], intensity(idxl_filter), [nrows, ncols], @mean, 0);</code></pre>

        <p>The resuling raster can be displayed with:</p>
        
        <pre><code>figure
imagesc(I);
axis equal tight
colorbar
caxis(quantile(I(:), [0.02, 0.98]))</code></pre>

            <figure>
                <img src="img/dft_tutorial_4_ima_3.png" alt="" style="width:80%;">
                <figcaption><b>Figure 3</b> - First returns intensity map.</figcaption>
            </figure>
            
            
        <p>Notice that the resulting intensity map is somewhat noisy due to the presence of small high intensity spots (near tree stems). You can optionally export the intensity map to an ARC/INFO ASCII grid file with the <code>ASCwrite()</code> function:</p>
        

<pre><code>ASCwrite('ge_2017_a_intensity.asc', ...
    I, ...
    refmat, ...
    'precision', 2, ...
    'noData', -99999, ...
    'verbose', true);</code></pre>
        
        
            <h2>
                <a id="step-5" class="anchor" href="step-5" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 5</b> - Segmentation
            </h2>
        
            <p>One simple approach to smooth the intensity map we obtained in the previous step is to apply segmentation and average the intensity in each segment. We will only illustrate the Simple Linear Iterative Clustering (SLIC) proposed by <a href="#references">Achanta et al. (2012)</a>, but other segmentation algorithms such as the marker controlled watershed segmention (cf. tutorial 2) could be used as well. SLIC is modified K-means algorithm, where the relative importance of spatial separation and color (or grayscale) similarity of clusters can be controlled with a compacity parameter. Matlab users who have access to the image processing toolbox can use the <code>superpixels()</code> function. Octave users (or Matlab users who dot not have the image processing toolbox) have to compile the SLICmex.c function provided by Achanta et al. (and included in the external functions directory of the Digital Forestry Toolbox), by typing the following line in the command window:</p>
        
        <pre><code>mex slicmex.c</code></pre>
        
            <p>Then run the following code:</p>
            
            <pre><code>segmentation = 'slic'; % specify 'slic' or 'watershed'

switch segmentation
    
    case 'slic' % Superpixel segmentation
        
        % rescale values to an 8 bit range (0-255)
        I_n = (I - quantile(I(:), 0.02)) ./ diff(quantile(I(:), [0.02, 0.98]));
        I_n = uint8(I_n * 255);
        
        % before running slicmex, you have to compile it with the following command:
        % mex slicmex.c
        [L, nlabels] = slicmex(I_n, ceil(0.05*nrows*ncols), 75);
        
        % Note: Matlab users who have the "image processing" toolbox can also use the superpixels() function
        % [L, nlabels] = superpixels(I_n, ceil(0.05*nrows*ncols), 'Compactness', 75);
        
    case 'watershed' % Marker controlled watershed segmentation
        
        [peaks_crh, ~] = canopyPeaks(models.height.values, ...
            refmat, ...
            'minTreeHeight', 2, ...
            'smoothingFilter', fspecial('gaussian', [3 3], 1), ...
            'searchRadius', @(h) 0.28 * h^0.59, ...
            'fig', false, ...
            'verbose', true);
        
        [L, ~] = treeWatershed(models.height.values, ...
            'markers', peaks_crh(:,1:2), ...
            'minHeight', 1, ...
            'removeBorder', false, ...
            'fig', false, ...
            'verbose', true);
        
end</code></pre>
            
            <h2>
                <a id="step-6" class="anchor" href="step-6" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 6</b> - Compute segment level intensity
            </h2>

            <p>We now compute the mean intensity and height of each segment with:</p>

            <pre><code>I_s = accumarray(L(:)+1, I(:), [nrows*ncols,1], @nanmean, nan);
I_s = I_s(L+1);
</code></pre>

            <pre><code>H_s = accumarray(L(:)+1, models.height.values(:), [nrows*ncols,1], @nanmean, single(nan));
H_s = H_s(L+1);</code></pre>

            <p>We then remove segments with an average height smaller than 3 m and those containing only null intensity values:</p>
            
            <pre><code>h_min = 3;
I_s(H_s <= h_min) = nan;

I_s(I_s == 0) = nan;</code></pre>
                
            
            <h2>
                <a id="step-7" class="anchor" href="step-7" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 7</b> - Create a classification map
            </h2>

            
<p>We start by examining the distribution of intensity values with a histogram:</p>
            
<pre><code>figure
hist(I_s(~isnan(I_s)), 100)
xlabel('intensity')
ylabel('count')
</code></pre>

            <figure>
                <img src="img/dft_tutorial_4_ima_4.png" alt="" style="width:80%;">
                <figcaption><b>Figure 4</b> - Histogram of average segment intensity values.</figcaption>
            </figure>
            
            <p>Notice the bimodal distribution, with two peaks around 12'000 and 20'000. To separate non-tree, deciduous and evergreen areas, we can split the values into low (&lt; 7500), medium (&ge; 7500 to &lt; 17'000) and high (&ge; 17'000) intensity categories with the <code>histc()</code> function:</p>

            <pre><code>[~, C] = histc(I_s(:), [7500, 17000, inf]);</code></pre>

            <p>We then reshape the intensity categories vector into an array and plot it:</p>

            <pre><code>C = reshape(C, nrows, ncols);
figure
imagesc(C)
axis equal tight
</code></pre>
            
            <h2>
                <a id="step-8" class="anchor" href="step-8" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Step 8</b> - Filter out small patches
            </h2>

            <p>To remove small patches in the evergreen category (C = 2), we apply <a href="https://ch.mathworks.com/help/images/understanding-morphological-reconstruction.html">morphological reconstruction</a> to the category 2 boolean image, using a morphological erosion (with a disk shaped window with a 1 pixel radius) as the marker:</p>
            <pre><code>J = imreconstruct(imerode(C == 2, strel("disk", 1)), C == 2);
C(J ~= (C == 2)) = 1;</code></pre>

            <p>Finally, you can optionally export the category map to an ARC/INFO ASCII grid file with the <code>ASCwrite()</code> function:</p>
            
           <pre><code>ASCwrite('ge_2017_a_class.asc', ...
    C, ...
    refmat, ...
    'precision', 0, ...
    'noData', -99999, ...
    'verbose', true);</code></pre>
    
           <p>After exporting the map, you can try opening it in any GIS software (e.g. <a href="http://www.qgis.org">Quantum GIS</a>). The interactive map below illustrates the categorical map overlayed on a leaf-off orthoimage of the same area (try moving the transparency slider to compare it with the orthoimage). Note that the features in the LiDAR derived map and in the orthoimage do not overlap perfectly. This is due to the orthorectification process which used a terrain model instead of a surface model.</p>

            <div id="map2">
            
            <div class="slidecontainer">
              <input type="range" min="0" max="1" value="0.2" step="0.01" class="slider" id="myRange" oninput="rasterStaticLayer2.setOpacity(this.value)">
            </div>

            </div>
            
        
            
        
            <h2>
                <a id="references" class="anchor" href="references" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>References</b>
            </h2>

            <ul>

                <li>Achanta, R., Shaji, A., Smith, K., Lucchi, A., Fua, P., Süsstrunk, S., 2012. <a href="https://ivrl.epfl.ch/research-2/research-current/research-superpixels/">SLIC Superpixels Compared to State-of-the-Art Superpixel Methods</a>. IEEE Transactions on Pattern Analysis and Machine Intelligence 34, 2274–2282. https://doi.org/10.1109/TPAMI.2012.120</li>

                <li>Höfle, B., Pfeifer, N., 2007. <a href="https://www.sciencedirect.com/science/article/pii/S0924271607000603">Correction of laser scanning intensity data: Data and model-driven approaches</a>. ISPRS Journal of Photogrammetry and Remote Sensing 62, 415–433. https://doi.org/10.1016/j.isprsjprs.2007.05.008</li>
                
                <li>Kashani, A.G., Olsen, M.J., Parrish, C.E., Wilson, N., 2015. <a href="https://www.mdpi.com/1424-8220/15/11/28099">A Review of LIDAR Radiometric Processing: From Ad Hoc Intensity Correction to Rigorous Radiometric Calibration</a>. Sensors 15, 28099–28128. https://doi.org/10.3390/s151128099</li>

                <li>Liang, X., Hyyppä, J., Matikainen, L., 2007. <a href="http://www.isprs.org/proceedings/XXXVI/3-W52/final_papers/Liang_2007.pdf">Deciduous-coniferous tree classification using difference between first and last pulse laser signatures</a>. International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences 36, 253–257.</li>

                <li>Luzum, B., Starek, M., Slatton, K.C., 2004. <a href="https://www.researchgate.net/publication/266228111_Normalizing_ALSM_Intensities">Normalizing ALSM intensities (No. Rep_2004-07-01)</a>, Geosensing Engineering and Mapping (GEM) Center. Civil and Coastal Engineering Department, University of Florida, Gainesville, FL, USA.</li>

                <li>Ørka, H. O., Næsset, E., Bollandsås, O. M., Jun. 2009. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0034425709000376">Classifying species of individual trees by intensity and structure features derived from airborne laser scanner data</a>. Remote Sensing of Environment 113 (6), 1163–1174.</li>
                
                <li>Riegl Laser Measurement Systems, 2017. <a href="http://www.riegl.com/uploads/tx_pxpriegldownloads/Whitepaper_LASextrabytes_implementation_in-RIEGLSoftware_2017-12-04.pdf">LAS Extrabytes Implementation in RIEGL Software</a>. Riegl Laser Measurement Systems GmbH, Horn, Riedenburgstrasse 48, Austria.</li>

                <li>Shi, Y., Wang, T., Skidmore, A. K., Heurich, M., Mar. 2018b. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0924271618300315">Important LiDAR metrics for discriminating forest tree species in Central Europe</a>. ISPRS Journal of Photogrammetry and Remote Sensing 137, 163–174.</li>
                
                <li>Vain, A., Kaasalainen, S., 2011. <a href="http://cdn.intechopen.com/pdfs/15799/InTech-Correcting_airborne_laser_scanning_intensity_data.pdf">Correcting airborne laser scanning intensity data</a>. INTECH Open Access Publisher.</li>

            </ul>

            <footer class="site-footer">
                <span class="site-footer-owner"><a href="https://github.com/mparkan/Digital-Forestry-Toolbox">Digital-forestry-toolbox</a> is maintained by <a href="https://github.com/mparkan">mparkan</a>.</span>

            </footer>

        </section>

        <script>

            // add CH1903 and CH1903+ CRS definitions
            if (proj4) {
                proj4.defs("EPSG:21781","+proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=600000 +y_0=200000 +ellps=bessel +towgs84=674.4,15.1,405.3,0,0,0,0 +units=m +no_defs");
                proj4.defs("EPSG:2056", "+proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=2600000 +y_0=1200000 +ellps=bessel +towgs84=674.374,15.056,405.346,0,0,0,0 +units=m +no_defs");
                ol.proj.proj4.register(proj4);
            };

            // define tile grid
            var extent = [2499100.0000000000000000,1127220.0000000000000000, 2499780.0000000000000000,1127900.0000000000000000]; // [minx, miny, maxx, maxy].
            var minZoom = 0;
            var maxZoom = 5;
            var startResolution = (extent[2]-extent[0]) / 256;
            var pixelResolutions = new Array(maxZoom + 1);
            for (var i = 0, ii = pixelResolutions.length; i < ii; ++i) {
                pixelResolutions[i] = startResolution / Math.pow(2, i);
            }
            var mapTileGrid = new ol.tilegrid.TileGrid({
                extent: extent,
                resolutions: pixelResolutions
            });

/*            // define vector layer
            var vectorLayer1 = new ol.layer.Vector({
                title: 'Tree tops',
                type: 'overlay',
                source: new ol.source.Vector({
                    format: new ol.format.GeoJSON(),
                    url: 'http://mparkan.github.io/Digital-Forestry-Toolbox/data/tutorial_2/vector/zh_2014_a_peaks.geojson',
                    crossOrigin: 'anonymous',
                    projection: 'EPSG:2056',
                }),
                style: new ol.style.Style({
                    image: new ol.style.Circle( ({
                        radius: 2,
                        fill: new ol.style.Fill({
                            color: '#ffff00'
                        })
                    }))
                })
            });*/
            
            // define XYZ tiles layer
            var rasterTileLayer1 = new ol.layer.Tile({
                title: 'RGB image',
                type: 'base',
                source: new ol.source.XYZ({
                    url: 'http://mparkan.github.io/Digital-Forestry-Toolbox/data/tutorial_3/raster/ortho/{z}/{x}/{y}.jpg',
                    crossOrigin: 'anonymous',
                    tileGrid: mapTileGrid,
                    projection: 'EPSG:2056',
                    opaque: false,
                    attributions: ['Data courtesy of <a href=https://ge.ch/sitg/donnees>Geneva</a>']
                })
            });

            
            // define static image layer
            var rasterStaticLayer1 = new ol.layer.Image({
                title: 'Canopy return intensity',
                type: 'base',
                opacity: 1.0,
                source: new ol.source.ImageStatic({
                    url: 'http://mparkan.github.io/Digital-Forestry-Toolbox/data/tutorial_4/raster/ge_2017_a_intensity.png',
                    crossOrigin: 'anonymous',
                    projection: 'EPSG:2056',
                    imageSize: [681,681],
                    imageExtent: extent,
                    attributions: 'Data courtesy of <a href=https://ge.ch/sitg/donnees>Geneva</a>'
                })
            });
            
            
            // define static image layer
            var rasterStaticLayer2 = new ol.layer.Image({
                title: 'Classification',
                type: 'base',
                opacity: 0.2, 
                source: new ol.source.ImageStatic({
                    url: 'http://mparkan.github.io/Digital-Forestry-Toolbox/data/tutorial_4/raster/ge_2017_a_class.png',
                    crossOrigin: 'anonymous',
                    projection: 'EPSG:2056',
                    imageSize: [681,681],
                    imageExtent: extent,
                    attributions: 'Data courtesy of <a href=https://ge.ch/sitg/donnees>Geneva</a>'
                })
            });
            
            
            // define scale bar control
            var scaleLineControl = new ol.control.ScaleLine();

            // define attribution control
            var attributionControl = new ol.control.Attribution({
                collapsible: true,
                className: 'ol-attribution'
            });

            // define fullscreen control
            var icon1 = document.createElement("expand_icon");
            icon1.className = "fa fa-expand";

            var fullScreenControl = new ol.control.FullScreen({
                label: icon1
            });

            // layer switcher control
            var layerSwitcherControl = new ol.control.LayerSwitcher({
                tipLabel: 'Layers'
            });


            var layerGroup1 = new ol.layer.Group({
                title: 'Basemaps',
                layers: [
                    rasterTileLayer1,
                    rasterStaticLayer2
                    //rasterStaticLayer1,
                ]
            });


/*            var layerGroup2 = new ol.layer.Group({
                title: 'Overlays',
                layers: [
                    vectorLayer1
                ]
            });*/


            // initialize map
            var map = new ol.WebGLMap({
                target: 'map2',
                controls: ol.control.defaults({attribution: false}).extend([
                    scaleLineControl,
                    attributionControl,
                    fullScreenControl
                    //layerSwitcherControl
                ]),
                interactions: ol.interaction.defaults().extend([
                    new ol.interaction.DragRotateAndZoom()
                ]),
                layers: [
                    layerGroup1
                ],
                view: new ol.View({
                    extent: extent,
                    center: ol.extent.getCenter(extent),
                    projection: ol.proj.get('EPSG:2056'),
                    zoom: 2,
                    minZoom: 1,
                    maxZoom: 6,
                    maxResolution: mapTileGrid.getResolution(minZoom)
                })
            });


        </script>

    </body>

</html>
